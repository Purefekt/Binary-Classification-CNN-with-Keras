{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1b0c7fa",
   "metadata": {},
   "source": [
    "# For Comparison, Training the Same Model With CPU\n",
    "\n",
    "First we have to change backend to CPU using plaidML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d80f05",
   "metadata": {},
   "source": [
    "To use PlaidML as backend follow these steps:\n",
    "- activate project environment\n",
    "- `plaidml-setup`\n",
    "- `Enable experimental device support? (y,n)[n]:n`\n",
    "- `Please choose a default device: 1` option 1 is always the CPU\n",
    "- `Save settings to /Users/veersingh/.plaidml? (y,n)[y]:y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef4ab83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries and set backend to plaidML\n",
    "from os import environ\n",
    "environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\"\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import time\n",
    "from keras import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Dropout\n",
    "import json\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d233c0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the paths\n",
    "train_dataset_path = '/Users/veersingh/Desktop/cats_dogs/train'\n",
    "valid_dataset_path = '/Users/veersingh/Desktop/cats_dogs/valid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e72e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rescale\n",
    "train = ImageDataGenerator(rescale=1 / 255)\n",
    "valid = ImageDataGenerator(rescale=1 / 255)\n",
    "\n",
    "# Define train and valid dataset\n",
    "# This method is useful since our images are in their respective class folders\n",
    "\n",
    "# seed = random number to maintain same output everytime\n",
    "# directory = path of train or valid dataset\n",
    "# target_size = resize the input image to required shape\n",
    "# batch_size = default batch size of 32\n",
    "# class_mode = categorical for multiclass\n",
    "# color_mode = depending on number of channels required by model, grayscale for 1 channel, rgb for 3 channel\n",
    "\n",
    "train_dataset = train.flow_from_directory(seed=1,\n",
    "                                          directory=train_dataset_path,\n",
    "                                          target_size=(100, 100),\n",
    "                                          batch_size=32,\n",
    "                                          class_mode = 'binary',\n",
    "                                          color_mode='rgb')\n",
    "\n",
    "valid_dataset = valid.flow_from_directory(seed=1,\n",
    "                                         directory=valid_dataset_path,\n",
    "                                         target_size=(100, 100),\n",
    "                                         batch_size=32,\n",
    "                                         class_mode = 'binary',\n",
    "                                         color_mode='rgb')\n",
    "\n",
    "# print labels\n",
    "print('\\n')\n",
    "print(f'Label for cat -> {train_dataset.class_indices[\"cat\"]}')\n",
    "print(f'Label for dog -> {train_dataset.class_indices[\"dog\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07bc400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model = Sequential()\n",
    "\n",
    "# Convolutional layer 1\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3),activation='relu',input_shape=(100, 100, 3)))\n",
    "\n",
    "# Maxpool layer 1\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Convolutional layer 2\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "\n",
    "# Maxpool layer 2\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Convolutional layer 3\n",
    "model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))\n",
    "\n",
    "# Maxpool layer 3\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Convolutional layer 4\n",
    "model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))\n",
    "\n",
    "# Maxpool layer 4\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flatten to 1D\n",
    "model.add(Flatten())\n",
    "\n",
    "# Fully connected layer with 512 neurons\n",
    "model.add(Dense(units=512, activation='relu'))\n",
    "\n",
    "# Output layer with single neuron which gives 0 for cat and 1 for dog\n",
    "model.add(Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34b347a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbb116c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce36bef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "\n",
    "# start the timer\n",
    "start_time = time.time()\n",
    "\n",
    "# generator = input training data created using ImageDataGenerator\n",
    "# steps_per_epoch = number of total training images/batch size = 16000/32 = 500\n",
    "# epochs = number of times we go through the entire training dataset\n",
    "# validation_data = validation dataset\n",
    "# verbose = it will print updates on every epoch\n",
    "\n",
    "model.fit_generator(generator=train_dataset,\n",
    "                              steps_per_epoch=500,\n",
    "                              epochs=30,\n",
    "                              validation_data=valid_dataset,\n",
    "                              verbose=2)\n",
    "\n",
    "# save the model\n",
    "model.save('models/cats_dogs_trained_model.h5')\n",
    "\n",
    "# stop the timer\n",
    "time_elapsed = round(time.time()-start_time, 2)\n",
    "\n",
    "print(f'\\n\\nThe model took {time_elapsed} seconds to train' )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd89ec1",
   "metadata": {},
   "source": [
    "## Save time taken to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff99a96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "log = {\"time_to_train_cpu\":time_elapsed}\n",
    "\n",
    "with open(\"log_cpu.json\", \"w\") as data_file:\n",
    "    json.dump(log, data_file, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lenet_alexnet",
   "language": "python",
   "name": "lenet_alexnet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
