{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87180913",
   "metadata": {},
   "source": [
    "# Custom CNN in Keras with GPU\n",
    "\n",
    "- I built this custom CNN using Keras\n",
    "- The model was trained on AMD GPU with PlaidML backend. I did not use TensorFlow since i do not have an Nvidia GPU, but that can be changed by setting `environ[\"KERAS_BACKEND\"] = \"tensorflow\"`\n",
    "- This model can classify dogs and cats\n",
    "- The training dataset consists of 8000 images for both cats and dogs, total of 16000 images\n",
    "- The validation dataset consists of 3500 images for both cats and dogs, total of 7000 images\n",
    "- The testing dataset consists of 1000 images for both cats and dogs, total of 2000 images\n",
    "- In total we have 25000 images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2e345f",
   "metadata": {},
   "source": [
    "## Import all libraries and set backend to PlaidML\n",
    "\n",
    "To use PlaidML as backend follow these steps:\n",
    "- activate project environment\n",
    "- `plaidml-setup`\n",
    "- `Enable experimental device support? (y,n)[n]:n`\n",
    "- `Please choose a default device: 3` most probably 1 would be your CPU, 2 would be the integrated GPU of your CPU and 3 would be your dedicated GPU\n",
    "- `Save settings to /Users/veersingh/.plaidml? (y,n)[y]:y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73cd82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries and set backend to plaidML\n",
    "from os import environ\n",
    "environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\"\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import time\n",
    "from keras import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Dropout\n",
    "import json\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac3eea6",
   "metadata": {},
   "source": [
    "## Preprocessing the data\n",
    "\n",
    "- First we need to rescale the pixel values. Currently the pixel values are in the range [0,255] since we are using 8 bit color or 2^8 values per pixel. We can just divide each pixel value with 255 and that will rescale all pixels to the range [0,1]. This reduces computation.\n",
    "- Next we need to label and resize the image since the model accepts images of the fixed size 100x100x3 where the image is 100 pixels in length and width and has 3 channels RGB. We can do this automatically by using ImageDataGenerator which has the method flow_from_director."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e738b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the paths\n",
    "train_dataset_path = '/Users/veersingh/Desktop/cats_dogs/train'\n",
    "valid_dataset_path = '/Users/veersingh/Desktop/cats_dogs/valid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4191212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rescale\n",
    "train = ImageDataGenerator(rescale=1 / 255)\n",
    "valid = ImageDataGenerator(rescale=1 / 255)\n",
    "\n",
    "# Define train and valid dataset\n",
    "# This method is useful since our images are in their respective class folders\n",
    "\n",
    "# seed = random number to maintain same output everytime\n",
    "# directory = path of train or valid dataset\n",
    "# target_size = resize the input image to required shape\n",
    "# batch_size = default batch size of 32\n",
    "# class_mode = categorical for multiclass\n",
    "# color_mode = depending on number of channels required by model, grayscale for 1 channel, rgb for 3 channel\n",
    "\n",
    "train_dataset = train.flow_from_directory(seed=1,\n",
    "                                          directory=train_dataset_path,\n",
    "                                          target_size=(100, 100),\n",
    "                                          batch_size=32,\n",
    "                                          class_mode = 'binary',\n",
    "                                          color_mode='rgb')\n",
    "\n",
    "valid_dataset = valid.flow_from_directory(seed=1,\n",
    "                                         directory=valid_dataset_path,\n",
    "                                         target_size=(100, 100),\n",
    "                                         batch_size=32,\n",
    "                                         class_mode = 'binary',\n",
    "                                         color_mode='rgb')\n",
    "\n",
    "# print labels\n",
    "print('\\n')\n",
    "print(f'Label for cat -> {train_dataset.class_indices[\"cat\"]}')\n",
    "print(f'Label for dog -> {train_dataset.class_indices[\"dog\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf1f8bd",
   "metadata": {},
   "source": [
    "## Create the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bd2683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model = Sequential()\n",
    "\n",
    "# Convolutional layer 1\n",
    "model.add(Conv2D(32, (3, 3),activation='relu',input_shape=(100, 100, 3)))\n",
    "\n",
    "# Maxpool layer\n",
    "model.add(MaxPooling2D(2, 2))\n",
    "\n",
    "# Convolutional layer 2and maxpool layer 2\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "# Maxpool layer\n",
    "model.add(MaxPooling2D(2, 2))\n",
    "\n",
    "# Convolutional layer 3\n",
    "model.add(keras.layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "\n",
    "# Maxpool layer\n",
    "model.add(keras.layers.MaxPool2D(2, 2))\n",
    "\n",
    "# Convolutional layer 4\n",
    "model.add(keras.layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "\n",
    "# Maxpool layer\n",
    "model.add(keras.layers.MaxPooling2D(2, 2))\n",
    "\n",
    "# Flatten to 1D\n",
    "model.add(keras.layers.Flatten())\n",
    "\n",
    "# Fully connected layer with 512 neurons\n",
    "model.add(keras.layers.Dense(512, activation='relu'))\n",
    "\n",
    "# Output layer with single neuron which gives 0 for cat and 1 for dog\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73ad0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03eba39",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6faf3f06",
   "metadata": {},
   "source": [
    "## Train and Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576aafbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "\n",
    "# start the timer\n",
    "start_time = time.time()\n",
    "\n",
    "# generator = input training data created using ImageDataGenerator\n",
    "# steps_per_epoch = number of total training images/batch size = 16000/32 = 500\n",
    "# epochs = number of times we go through the entire training dataset\n",
    "# validation_data = validation dataset\n",
    "# verbose = it will print updates on every epoch\n",
    "\n",
    "history = model.fit_generator(generator=train_dataset,\n",
    "                              steps_per_epoch=500,\n",
    "                              epochs=30,\n",
    "                              validation_data=valid_dataset,\n",
    "                              verbose=2)\n",
    "\n",
    "# save the model\n",
    "model.save('cats_dogs_trained_model.h5')\n",
    "\n",
    "# stop the timer\n",
    "time_elapsed = round(time.time()-start_time, 2)\n",
    "\n",
    "print(f'\\n\\nThe model took {time_elapsed} seconds' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fb7a04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lenet_alexnet",
   "language": "python",
   "name": "lenet_alexnet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
